{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "project_asr2onnx.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1Cyg8y6lnkUYuwugPaZSm2G3n4M0P1m5C",
      "authorship_tag": "ABX9TyMa7z8vDF/bYm183plE+nuw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Intraraksa/restructure_meta_human/blob/master/asr/project_asr2onnx.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Asr project \n",
        "This is the Botnoi project for chang asr (auto speech recognition to onnx)\n",
        "ในโปรเจคนี้เป็นการแปลง Pretrain model wav2vec โมเดลที่ถูกเทรนของ Botnoi เพื่อแปลงเป็น Onnx Model เนื่องจากต้องการให้ Model มีขนาดที่เล็กลง\n",
        "\n",
        "1. ใน section แรกจะเป็นการแปลง huggingface pytorch model เป็น onnx \n",
        "2. เป็นการ inference model"
      ],
      "metadata": {
        "id": "pt0BJR1PFnlZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Convert model"
      ],
      "metadata": {
        "id": "gk4wlFa-9P1w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### install dependencies and import dependencies"
      ],
      "metadata": {
        "id": "eN16sQO9F1N3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fd5Og3buEdcS",
        "outputId": "d72fc7dc-f6e2-4b32-c282-6b7c433ba56f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.19.0-py3-none-any.whl (4.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.2 MB 34.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.3)\n",
            "Collecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.6.0-py3-none-any.whl (84 kB)\n",
            "\u001b[K     |████████████████████████████████| 84 kB 3.0 MB/s \n",
            "\u001b[?25hCollecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
            "  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 19.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Collecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 27.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.2.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.8)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Installing collected packages: pyyaml, tokenizers, huggingface-hub, transformers\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed huggingface-hub-0.6.0 pyyaml-6.0 tokenizers-0.12.1 transformers-4.19.0\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import dependenciies ที่จะใช้งานในขั้นตอนการแปลงไฟล์ โดย model ที่ pretrain ไว้จะอยู่ใน Folder ซึ่งจะรวมอยู่กับ utility ต่างๆ ดังนี้ (ในโปรเจคนี้จะเก็บใน Google Drive)\n",
        "\n",
        "![image.png](data:image/png;base64,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)"
      ],
      "metadata": {
        "id": "h7ssu0ewG_wR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import transformers\n",
        "from transformers import AutoTokenizer, Wav2Vec2ForCTC\n",
        "from torchaudio.models.wav2vec2.utils import import_huggingface_model\n",
        "import torch.onnx"
      ],
      "metadata": {
        "id": "vsa0CtHvFYzz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### load pytorch model"
      ],
      "metadata": {
        "id": "AAXIBX5b9YoS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## โหลด Pretrained model \n",
        "original = Wav2Vec2ForCTC.from_pretrained('/content/drive/MyDrive/last-20220125_224500')\n",
        "## สร้าง Model pytorch ที่ inference เสียงพูด\n",
        "model = import_huggingface_model(original)"
      ],
      "metadata": {
        "id": "3hlL0seII96u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(type(original))\n",
        "print(type(model))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wnAiQOTqJrz-",
        "outputId": "ffac5d26-1aa0-45fa-854b-915a8010c167"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'transformers.models.wav2vec2.modeling_wav2vec2.Wav2Vec2ForCTC'>\n",
            "<class 'torchaudio.models.wav2vec2.model.Wav2Vec2Model'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### convert model\n",
        "ขั้นตอนการแปลงเป็น ONNX \n",
        "โดยในขั้นตอนการแปลงไฟล์เป็น ONNX จาก Pytorch \n",
        "มีข้อจำกัดคือ ต้องมีการกำหนด dummy input ซึ่งมีการ fix size ตายตัว"
      ],
      "metadata": {
        "id": "Sz7EUaUfMNlZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_size = 100000\n",
        "AUDIO_MAXLEN = input_size\n",
        "\n",
        "dummy_input = torch.randn(1, input_size, requires_grad=True)"
      ],
      "metadata": {
        "id": "dB2cwUDLJy0U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.onnx.export(model,         # model being run\n",
        "         dummy_input,       # model input (or a tuple for multiple inputs)\n",
        "         \"/content/drive/MyDrive/last-20220125_224500/asr_botnoi11.onnx\",       # where to save the model\n",
        "         export_params=True,  # store the trained parameter weights inside the model file\n",
        "         opset_version=10,    # the ONNX version to export the model to\n",
        "         do_constant_folding=True,  # whether to execute constant folding for optimization\n",
        "         input_names = ['modelInput'],   # the model's input names\n",
        "         output_names = ['modelOutput'], # the model's output names\n",
        "         dynamic_axes={'modelInput' : {0 : 'batch_size'},    # variable length axes\n",
        "                                'modelOutput' : {0 : 'batch_size'}})"
      ],
      "metadata": {
        "id": "jNRRH-biNhlx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## inference model"
      ],
      "metadata": {
        "id": "DrzuNu2n99If"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install onnxruntime"
      ],
      "metadata": {
        "id": "Lf4qgulzN3Sc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "22851450-cb9f-437a-e05e-a371a04a6c24"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting onnxruntime\n",
            "  Downloading onnxruntime-1.11.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.2 MB 29.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.7/dist-packages (from onnxruntime) (1.21.6)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.7/dist-packages (from onnxruntime) (3.17.3)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.7/dist-packages (from onnxruntime) (2.0)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf->onnxruntime) (1.15.0)\n",
            "Installing collected packages: onnxruntime\n",
            "Successfully installed onnxruntime-1.11.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt-get install libportaudio2\n",
        "!sudo apt-get install libasound-dev"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fP80Z7P--skK",
        "outputId": "7afc0b5a-df39-4ae7-948f-b669ff06cd7e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following packages were automatically installed and are no longer required:\n",
            "  libnvidia-common-460 nsight-compute-2020.2.0\n",
            "Use 'sudo apt autoremove' to remove them.\n",
            "The following NEW packages will be installed:\n",
            "  libportaudio2\n",
            "0 upgraded, 1 newly installed, 0 to remove and 42 not upgraded.\n",
            "Need to get 64.6 kB of archives.\n",
            "After this operation, 215 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libportaudio2 amd64 19.6.0-1 [64.6 kB]\n",
            "Fetched 64.6 kB in 1s (81.5 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 1.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package libportaudio2:amd64.\n",
            "(Reading database ... 155203 files and directories currently installed.)\n",
            "Preparing to unpack .../libportaudio2_19.6.0-1_amd64.deb ...\n",
            "Unpacking libportaudio2:amd64 (19.6.0-1) ...\n",
            "Setting up libportaudio2:amd64 (19.6.0-1) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1.3) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/python3.7/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n",
            "\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "Note, selecting 'libasound2-dev' instead of 'libasound-dev'\n",
            "libasound2-dev is already the newest version (1.1.3-5ubuntu0.6).\n",
            "The following packages were automatically installed and are no longer required:\n",
            "  libnvidia-common-460 nsight-compute-2020.2.0\n",
            "Use 'sudo apt autoremove' to remove them.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 42 not upgraded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sounddevice pythainlp soundfile"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wI_Mp9Ej-C6d",
        "outputId": "05eb703f-91cd-4656-a2be-aa9ebe0b7bd1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting sounddevice\n",
            "  Downloading sounddevice-0.4.4-py3-none-any.whl (31 kB)\n",
            "Collecting pythainlp\n",
            "  Downloading pythainlp-3.0.5-py3-none-any.whl (11.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 11.5 MB 52.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: soundfile in /usr/local/lib/python3.7/dist-packages (0.10.3.post1)\n",
            "Requirement already satisfied: CFFI>=1.0 in /usr/local/lib/python3.7/dist-packages (from sounddevice) (1.15.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from CFFI>=1.0->sounddevice) (2.21)\n",
            "Collecting tinydb>=3.0\n",
            "  Downloading tinydb-4.7.0-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: requests>=2.22.0 in /usr/local/lib/python3.7/dist-packages (from pythainlp) (2.23.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.22.0->pythainlp) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.22.0->pythainlp) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.22.0->pythainlp) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.22.0->pythainlp) (2.10)\n",
            "Requirement already satisfied: typing-extensions<5.0.0,>=3.10.0 in /usr/local/lib/python3.7/dist-packages (from tinydb>=3.0->pythainlp) (4.2.0)\n",
            "Installing collected packages: tinydb, sounddevice, pythainlp\n",
            "Successfully installed pythainlp-3.0.5 sounddevice-0.4.4 tinydb-4.7.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sounddevice as sd\n",
        "import numpy as np\n",
        "import onnxruntime as rt\n",
        "import scipy.signal as sps\n",
        "from datetime import datetime\n",
        "from pythainlp.util import normalize"
      ],
      "metadata": {
        "id": "IBQOdlW8-Ug_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## inference onnx model"
      ],
      "metadata": {
        "id": "yam9qe-P_PNA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### create inference function"
      ],
      "metadata": {
        "id": "3XTSqccuDy_h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_size = 100000\n",
        "new_rate = 16000\n",
        "AUDIO_MAXLEN = input_size\n",
        "\n",
        "ort_session = rt.InferenceSession('/content/drive/MyDrive/last-20220125_224500/asr_botnoi.onnx')\n",
        "\n",
        "with open(\"/content/drive/MyDrive/last-20220125_224500/vocab.json\",\"r\",encoding=\"utf-8-sig\") as f:\n",
        "    d = eval(f.read())\n",
        "\n",
        "res = dict((v,k) for k,v in d.items())\n",
        "res[69]=\"[PAD]\"\n",
        "res[68]=\"[UNK]\"\n",
        "\n",
        "def _normalize(x): #\n",
        "    \"\"\"You must call this before padding.\n",
        "  Code from https://github.com/vasudevgupta7/gsoc-wav2vec2/blob/main/src/wav2vec2/processor.py#L101\n",
        "  Fork TF to numpy\n",
        "  \"\"\"\n",
        "  # -> (1, seqlen)\n",
        "    mean = np.mean(x, axis=-1, keepdims=True)\n",
        "    var = np.var(x, axis=-1, keepdims=True)\n",
        "    # return np.squeeze((x - mean) / np.sqrt(var + 1e-5))\n",
        "    res  =  np.squeeze((x - mean) / np.sqrt(var + 1e-5)) \n",
        "    mean = None\n",
        "    var  = None\n",
        "    return res\n",
        "\n",
        "def remove_adjacent(item): # code from https://stackoverflow.com/a/3460423\n",
        "    nums = list(item)\n",
        "    a = nums[:1]\n",
        "    for item in nums[1:]:\n",
        "        if item != a[-1]:\n",
        "            a.append(item)\n",
        "\n",
        "    nums = None\n",
        "    return ''.join(a)\n",
        "\n",
        "def asr(path):\n",
        "    \"\"\"\n",
        "    Code from https://github.com/vasudevgupta7/gsoc-wav2vec2/blob/main/notebooks/wav2vec2_onnx.ipynb\n",
        "    Fork TF to numpy\n",
        "    \"\"\"\n",
        "    # sampling_rate, data = wavfile.read(path)\n",
        "    samples = round(len(path) * float(new_rate) / freq)\n",
        "    new_data = sps.resample(recording, samples)\n",
        "    samples = None\n",
        "    speech = np.array(new_data, dtype=np.float32)\n",
        "    new_data = None\n",
        "    speech = _normalize(speech)[None]\n",
        "    padding = np.zeros((speech.shape[0], AUDIO_MAXLEN - speech.shape[1]))\n",
        "    speech = np.concatenate([speech, padding], axis=-1).astype(np.float32)\n",
        "    ort_inputs = {\"modelInput\": speech}\n",
        "    speech =  None\n",
        "    start = datetime.now()\n",
        "    ort_outs = ort_session.run(None, ort_inputs)\n",
        "    end = datetime.now()\n",
        "    print(end-start)\n",
        "    prediction = np.argmax(ort_outs, axis=-1)\n",
        "    ort_inputs =  None\n",
        "    ort_outs = None\n",
        "    # Text post processing\n",
        "    _t1 = ''.join([res[i] for i in list(prediction[0][0])])\n",
        "    prediction = None\n",
        "    return normalize(''.join([remove_adjacent(j) for j in _t1.split(\"[PAD]\")]))\n"
      ],
      "metadata": {
        "id": "9L5h3erX-gbS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sounddevice as sd\n",
        "import soundfile as sf\n",
        "\n",
        "freq = 44100\n",
        "\n",
        "filename = '/content/record.wav'\n",
        "# Extract data and sampling rate from file\n",
        "recording, fs = sf.read(filename, dtype='float32')  \n",
        "prediction = asr(recording)\n",
        "print(\"\".join(prediction.split('|')))"
      ],
      "metadata": {
        "id": "ovUGh3lk_k6-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ec6fb90-0e5d-43f8-d30e-a4251705a903"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0:00:03.475599\n",
            "ทดรองบันทึกเศษครั้งที่หนึ่งเดี๋ยมอดูผลลัพธ์กัดคับว่าเป็นยังไงบ้าง\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## inference model from huggingface model"
      ],
      "metadata": {
        "id": "ZPYLGGbSW6n6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, Wav2Vec2ForCTC,Wav2Vec2Processor\n",
        "import torch\n",
        "\n",
        "#load pretrained processor and model\n",
        "processor = Wav2Vec2Processor.from_pretrained('/content/drive/MyDrive/last-20220125_224500')\n",
        "model = Wav2Vec2ForCTC.from_pretrained('/content/drive/MyDrive/last-20220125_224500')\n",
        "\n",
        "freq = 44100\n",
        "\n",
        "def resampling(path):\n",
        "  samples = round(len(path) * float(new_rate) / freq)\n",
        "  new_data = sps.resample(path, samples)\n",
        "  return new_data\n",
        "\n",
        "# #function to resample to 16_000\n",
        "# def speech_file_to_array_fn(batch, \n",
        "#                             text_col=\"sentence\", \n",
        "#                             fname_col=\"path\",\n",
        "#                             resampling_to=16000):\n",
        "#     speech_array, sampling_rate = torchaudio.load(batch[fname_col])\n",
        "#     resampler=torchaudio.transforms.Resample(sampling_rate, resampling_to)\n",
        "#     batch[\"speech\"] = resampler(speech_array)[0].numpy()\n",
        "#     batch[\"sampling_rate\"] = resampling_to\n",
        "#     batch[\"target_text\"] = batch[text_col]\n",
        "#     return batch\n",
        "\n",
        "# #get 2 examples as sample input\n",
        "# test_dataset = test_dataset.map(speech_file_to_array_fn)\n",
        "# inputs = processor(test_dataset[\"speech\"][:2], sampling_rate=16_000, return_tensors=\"pt\", padding=True)\n",
        "\n",
        "# #infer\n",
        "# with torch.no_grad():\n",
        "#     logits = model(inputs.input_values,).logits\n",
        "\n",
        "# predicted_ids = torch.argmax(logits, dim=-1)\n",
        "\n",
        "# print(\"Prediction:\", processor.batch_decode(predicted_ids))\n",
        "# print(\"Reference:\", test_dataset[\"sentence\"][:2])\n",
        "\n",
        "# # >> Prediction: ['และ เขา ก็ สัมผัส ดีบุก', 'คุณ สามารถ รับทราบ เมื่อ ข้อความ นี้ ถูก อ่าน แล้ว']\n",
        "# # >> Reference: ['และเขาก็สัมผัสดีบุก', 'คุณสามารถรับทราบเมื่อข้อความนี้ถูกอ่านแล้ว']\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HV1tt8sTW_Ie",
        "outputId": "be38d4d9-89be-4ad7-975b-a327ec93db71"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_size = 100000\n",
        "new_rate = 16000\n",
        "AUDIO_MAXLEN = input_size\n",
        "\n",
        "def resampling(path):\n",
        "  samples = round(len(path) * float(new_rate) / freq)\n",
        "  new_data = sps.resample(path, samples)\n",
        "  return new_data\n",
        "\n",
        "new_data = resampling(recording)\n",
        "\n",
        "input_values = processor(new_data, sampling_rate=new_rate, return_tensors=\"pt\").input_values"
      ],
      "metadata": {
        "id": "kHwtYDi0XnXl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# retrieve logits & take argmax\n",
        "start = datetime.now()\n",
        "logits = model(input_values).logits\n",
        "predicted_ids = torch.argmax(logits, dim=-1)\n",
        "\n",
        "# transcribe\n",
        "transcription = processor.decode(predicted_ids[0])\n",
        "end = datetime.now()\n",
        "print(end-start)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BfN_dwGndR9g",
        "outputId": "043dd1b6-3033-4a85-81b4-7be790635c6c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0:00:03.468457\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transcription"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "l13lBPFGfRAc",
        "outputId": "f68373ec-2a73-4823-be84-d1ab5982e1b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'ทด รอง บันทึก เศษ  ครั้ง ที่ หนึ่ง   เดี๋ยม อ ดู ผล ลัพธ์ กัด คับ  ว่า เป็น ยัง ไง บ้าง'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "kJp1YBDJUwv6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}